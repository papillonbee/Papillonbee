{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Papillonbee.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papillonbee/Papillonbee/blob/master/Papillonbee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "IaS7ULdKZsXJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Papillonbee\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## A chatbot implemented with latent semantic indexing technique\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4bRiqDtveQLY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Author: Papan Yongmalwong"
      ]
    },
    {
      "metadata": {
        "id": "TSTkhWOk9W9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Motivation\n",
        "Suppose you have data of some texts that map to their own responses; e.g. \n",
        "\n",
        "'Hey baby' maps to 'yeah?'\n",
        "\n",
        "'Where are you' maps to 'I’m at my dorm'\n",
        "\n",
        "It would be an easy task to write a chatbot that makes response according to the data you have since it could be done with if-else statement; e.g. \n",
        "\n",
        "```\n",
        "if(INUPUT_TEXT == 'Hey baby'):\n",
        "     make_response('yeah?')\n",
        "```\n",
        "\n",
        "But what if the input text does not map to any of the texts, there would be no response made for the conversation. To overcome this problem, it would be best to identify the text that is most similar to the input text.\n",
        "\n",
        "## Goal\n",
        "To identify the text in your data that is most similar to the input text."
      ]
    },
    {
      "metadata": {
        "id": "APWNBtpcPaoN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "Apply a technique in natural language processing called [latent semantic indexing (LSI)](https://en.wikipedia.org/wiki/Latent_semantic_analysis).\n",
        "1.   Transform texts into vectors.\n",
        "2.   Take cosine of the angle between the 2 vectors (each text in your data and the input text) to measure similarity.\n",
        "3.   Choose the vector (the text in your data) with the highest similarity score.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DIaiQKHSZ5sd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The solution can be done in 5 steps:**\n",
        "\n",
        "**Step 1: Install gensim and pythainlp**\n",
        "*   Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing (NLP) and information retrieval (IR) community.\n",
        "*   PyThaiNLP is a Python package for text processing and linguistic analysis, similar to nltk but with focus on Thai language."
      ]
    },
    {
      "metadata": {
        "id": "knShdOlPYcLD",
        "colab_type": "code",
        "outputId": "d6637e9c-2708-4d1e-f4c6-495a457cb428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.67)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.67 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.67)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WnGNtUx_Yu23",
        "colab_type": "code",
        "outputId": "b89d07a9-9e2c-4018-d87c-8ee416ca494a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pythainlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pythainlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/cf/9beb2bcb6370e86f33d3b07cac514bf29352e3cb826828b00c1ca3efac72/pythainlp-1.7.1-py3-none-any.whl (10.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 10.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2018.7)\n",
            "Collecting conllu (from pythainlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/12/63/00094506b473b176be0a632e205d2a8b631cf42384b06d1e29eebf59f4da/conllu-1.2.1-py2.py3-none-any.whl\n",
            "Collecting tinydb (from pythainlp)\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/2b/98040184cfbf03113736a160ea35aa92dc3619312ba5a4d6cafaf7f81c73/tinydb-3.12.2-py2.py3-none-any.whl\n",
            "Collecting marisa-trie (from pythainlp)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K    100% |████████████████████████████████| 276kB 28.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pythainlp) (4.28.1)\n",
            "Requirement already satisfied: nltk>=3.2.2 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pythainlp) (1.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pythainlp) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pythainlp) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pythainlp) (2.6)\n",
            "Building wheels for collected packages: marisa-trie\n",
            "  Running setup.py bdist_wheel for marisa-trie ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built marisa-trie\n",
            "Installing collected packages: conllu, tinydb, marisa-trie, pythainlp\n",
            "Successfully installed conllu-1.2.1 marisa-trie-0.7.5 pythainlp-1.7.1 tinydb-3.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lX2wyfEjaFCo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 2: Load LINE conversation text file of** *Rabbit* **and** *Papillonbee*"
      ]
    },
    {
      "metadata": {
        "id": "FVjEREknY546",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "response = requests.get('https://gist.githubusercontent.com/papillonbee/227d8a1c26303c815614ade026906b4c/raw/c5b9745ce95d571a40190aa6128ef39973c43dab/rabbit_dictionary.txt')\n",
        "txt = response.text.replace('\\n','|')\n",
        "txt += '|'\n",
        "t = ''\n",
        "Rabbit = []\n",
        "for i in txt:\n",
        "    if i == '|':\n",
        "        Rabbit.append(t)\n",
        "        t = ''\n",
        "        continue\n",
        "    t += i\n",
        "response = requests.get('https://gist.githubusercontent.com/papillonbee/a18a99a59d9372c9b11e2d1828a26c14/raw/862a3cd0560d94fd1b6e00d6bf5490e96529b3e3/ppllnb.txt')\n",
        "txt = response.text.replace('\\n','|')\n",
        "txt += '|'\n",
        "t = ''\n",
        "Papillonbee = []\n",
        "for i in txt:\n",
        "    if i == '|':\n",
        "        Papillonbee.append(t)\n",
        "        t = ''\n",
        "        continue\n",
        "    t += i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oo1gidVCcAmb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 3: Create corpus from** *Rabbit* **, fit model, and define** *talk_with_Papillonbee*"
      ]
    },
    {
      "metadata": {
        "id": "rhPhODg-ZJsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models, similarities\n",
        "import pythainlp as tnlp\n",
        "my_text = [list(filter(lambda a: a != ' ' and a != '  ' and a != '   ', tnlp.word_tokenize(line.lower()))) for line in Rabbit]\n",
        "my_dictionary = corpora.Dictionary(my_text)\n",
        "my_corpus = [my_dictionary.doc2bow(text) for text in my_text]\n",
        "my_lsi = models.LsiModel(my_corpus, id2word=my_dictionary, num_topics=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gf7pwANWqoAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def talk_with_Papillonbee(INPUT_TEXT):\n",
        "  vec_bow = my_dictionary.doc2bow(list(filter(lambda a: a != ' ' and a != '  ' and a != '   ', tnlp.word_tokenize(INPUT_TEXT.lower()))))\n",
        "  vec_lsi = my_lsi[vec_bow]\n",
        "  my_index = similarities.MatrixSimilarity(my_lsi[my_corpus])\n",
        "  my_sims = my_index[vec_lsi]\n",
        "  arr = sorted(enumerate(my_sims), key=lambda item: -item[1])[:5]\n",
        "  output_text = Papillonbee[arr[0][0]]\n",
        "  top_5_list = ''\n",
        "  top_5_list += 'Top 5 most similar texts to \\'' + INPUT_TEXT + '\\':\\n'\n",
        "  for i in range(5):\n",
        "      top_5_list += str(i+1) + '.)' + str(Rabbit[arr[i][0]]) + ': ' + str(Papillonbee[arr[i][0]]) + '\\nCosine similarity = ' + str(arr[i][1])\n",
        "      if i != 4:\n",
        "          top_5_list += '\\n'\n",
        "  return output_text, top_5_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3EpxbPJor_Np",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 4: Input any text to talk with** *Papillonbee*"
      ]
    },
    {
      "metadata": {
        "id": "_QTrcowOqrU7",
        "colab_type": "code",
        "outputId": "57527c86-17b6-4a43-d350-b947fd7be3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "#Edit text here\n",
        "INPUT_TEXT = 'อะไร'\n",
        "response = talk_with_Papillonbee(INPUT_TEXT)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YZ5L6cFNc-Fh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 5: Print the response from ** *Papillonbee*"
      ]
    },
    {
      "metadata": {
        "id": "2fvpZ0pSZj6m",
        "colab_type": "code",
        "outputId": "2ac100aa-c012-45c2-ab5d-41985c396543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(response[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alright \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q4132jFoZOqx",
        "colab_type": "code",
        "outputId": "9225b6ee-d731-4ecd-ab6e-a4b3b9bafa44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "print(response[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 5 most similar texts to 'อะไร':\n",
            "1.)Cham 9 big: Alright \n",
            "Cosine similarity = 0.6558318\n",
            "2.)but มีอะไรติดขัดนิดหน่อย cham 9: Im billing now okay?\n",
            "Cosine similarity = 0.65380657\n",
            "3.)But doing อะไรก็ไม่รู้ i dont know how could I write it: Unless you can think of an idea which makes impact On all sales professionals \n",
            "Cosine similarity = 0.43805516\n",
            "4.)Oh 9 วิชาสามัญ: Not sure\n",
            "Cosine similarity = 0.35885912\n",
            "5.)HUHHHH: but idk if it is open\n",
            "Cosine similarity = 0.35167667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0W7Fa9tOUJ92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "Phatthiyaphaibun, W. (2018, June 4). *User manual PyThaiNLP 1.6*. Retrieved from https://github.com/PyThaiNLP/pythainlp/blob/dev/docs/pythainlp-1-6-eng.md\n",
        "\n",
        "Řehůřek, R. (2017, November 14). *gensim Documentation Release 0.8.6*. Retrieved from https://media.readthedocs.org/pdf/gensim/stable/gensim.pdf"
      ]
    },
    {
      "metadata": {
        "id": "6HA0_bdx1MxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Add Papillonbee on LINE and start to chat [here](https://line.me/R/ti/p/%40ban4934y)**\n",
        "\n",
        "**Full work is available [here](https://github.com/papillonbee/Papillonbee)**"
      ]
    }
  ]
}