{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Papillonbee.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papillonbee/Papillonbee/blob/master/Papillonbee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaS7ULdKZsXJ",
        "colab_type": "text"
      },
      "source": [
        "# Papillonbee\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## A chatbot implemented with latent semantic indexing technique\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bRiqDtveQLY",
        "colab_type": "text"
      },
      "source": [
        "Author: Papan Yongmalwong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSTkhWOk9W9B",
        "colab_type": "text"
      },
      "source": [
        "## Motivation\n",
        "Suppose you have data of some texts that map to their own responses; e.g. \n",
        "\n",
        "'Hey baby' maps to 'yeah?'\n",
        "\n",
        "'Where are you' maps to 'Iâ€™m at my dorm'\n",
        "\n",
        "It would be an easy task to write a chatbot that makes response according to the data you have since it could be done with if-else statement; e.g. \n",
        "\n",
        "```\n",
        "if(INUPUT_TEXT == 'Hey baby'):\n",
        "     make_response('yeah?')\n",
        "```\n",
        "\n",
        "But what if the input text does not map to any of the texts, there would be no response made for the conversation. To overcome this problem, it would be best to identify the text that is most similar to the input text.\n",
        "\n",
        "## Goal\n",
        "To identify the text in your data that is most similar to the input text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APWNBtpcPaoN",
        "colab_type": "text"
      },
      "source": [
        "## Solution\n",
        "Apply a technique in natural language processing called [latent semantic indexing (LSI)](https://en.wikipedia.org/wiki/Latent_semantic_analysis).\n",
        "1.   Transform texts into vectors.\n",
        "2.   Take cosine of the angle between the 2 vectors (each text in your data and the input text) to measure similarity.\n",
        "3.   Choose the vector (the text in your data) with the highest similarity score.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIaiQKHSZ5sd",
        "colab_type": "text"
      },
      "source": [
        "**The solution can be done in 5 steps:**\n",
        "\n",
        "**Step 1: Install gensim and pythainlp**\n",
        "*   Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing (NLP) and information retrieval (IR) community.\n",
        "*   PyThaiNLP is a Python package for text processing and linguistic analysis, similar to nltk but with focus on Thai language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knShdOlPYcLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnGNtUx_Yu23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pythainlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX2wyfEjaFCo",
        "colab_type": "text"
      },
      "source": [
        "**Step 2: Load LINE conversation text file of** *Rabbit* **and** *Papillonbee*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVjEREknY546",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "response = requests.get('https://gist.githubusercontent.com/papillonbee/227d8a1c26303c815614ade026906b4c/raw/c5b9745ce95d571a40190aa6128ef39973c43dab/rabbit_dictionary.txt')\n",
        "txt = response.text.replace('\\n','|')\n",
        "txt += '|'\n",
        "t = ''\n",
        "Rabbit = []\n",
        "for i in txt:\n",
        "    if i == '|':\n",
        "        Rabbit.append(t)\n",
        "        t = ''\n",
        "        continue\n",
        "    t += i\n",
        "response = requests.get('https://gist.githubusercontent.com/papillonbee/a18a99a59d9372c9b11e2d1828a26c14/raw/862a3cd0560d94fd1b6e00d6bf5490e96529b3e3/ppllnb.txt')\n",
        "txt = response.text.replace('\\n','|')\n",
        "txt += '|'\n",
        "t = ''\n",
        "Papillonbee = []\n",
        "for i in txt:\n",
        "    if i == '|':\n",
        "        Papillonbee.append(t)\n",
        "        t = ''\n",
        "        continue\n",
        "    t += i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo1gidVCcAmb",
        "colab_type": "text"
      },
      "source": [
        "**Step 3: Create corpus from** *Rabbit* **, fit model, and define** *talk_with_Papillonbee*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhPhODg-ZJsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import corpora, models, similarities\n",
        "import pythainlp as tnlp\n",
        "my_text = [list(filter(lambda a: a != ' ' and a != '  ' and a != '   ', tnlp.word_tokenize(line.lower()))) for line in Rabbit]\n",
        "my_dictionary = corpora.Dictionary(my_text)\n",
        "my_corpus = [my_dictionary.doc2bow(text) for text in my_text]\n",
        "my_lsi = models.LsiModel(my_corpus, id2word=my_dictionary, num_topics=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf7pwANWqoAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def talk_with_Papillonbee(INPUT_TEXT):\n",
        "  vec_bow = my_dictionary.doc2bow(list(filter(lambda a: a != ' ' and a != '  ' and a != '   ', tnlp.word_tokenize(INPUT_TEXT.lower()))))\n",
        "  vec_lsi = my_lsi[vec_bow]\n",
        "  my_index = similarities.MatrixSimilarity(my_lsi[my_corpus])\n",
        "  my_sims = my_index[vec_lsi]\n",
        "  arr = sorted(enumerate(my_sims), key=lambda item: -item[1])[:5]\n",
        "  output_text = Papillonbee[arr[0][0]]\n",
        "  top_5_list = ''\n",
        "  top_5_list += 'Top 5 most similar texts to \\'' + INPUT_TEXT + '\\':\\n'\n",
        "  for i in range(5):\n",
        "      top_5_list += str(i+1) + '.)' + str(Rabbit[arr[i][0]]) + ': ' + str(Papillonbee[arr[i][0]]) + '\\nCosine similarity = ' + str(arr[i][1])\n",
        "      if i != 4:\n",
        "          top_5_list += '\\n'\n",
        "  return output_text, top_5_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EpxbPJor_Np",
        "colab_type": "text"
      },
      "source": [
        "**Step 4: Input any text to talk with** *Papillonbee*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QTrcowOqrU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "67484998-aba3-425c-bdf7-91a072e14391"
      },
      "source": [
        "#Edit text here\n",
        "INPUT_TEXT = 'Hey baby whats up'\n",
        "response = talk_with_Papillonbee(INPUT_TEXT)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ5L6cFNc-Fh",
        "colab_type": "text"
      },
      "source": [
        "**Step 5: Print the response from** *Papillonbee*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fvpZ0pSZj6m",
        "colab_type": "code",
        "outputId": "5909714e-2441-4939-abc0-593eae53c120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(response[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yeah?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4132jFoZOqx",
        "colab_type": "code",
        "outputId": "efef6a5c-e1e3-4a3b-a20a-2517987a76d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print(response[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 5 most similar texts to 'Hey baby whats up':\n",
            "1.)Hey baby: yeah?\n",
            "Cosine similarity = 0.84603983\n",
            "2.)Hey baby: ?\n",
            "Cosine similarity = 0.84603983\n",
            "3.)Sticker Hey baby: Huh?\n",
            "Cosine similarity = 0.6877541\n",
            "4.)Baby: hey there\n",
            "Cosine similarity = 0.60257614\n",
            "5.)Hey: Huh?\n",
            "Cosine similarity = 0.59982234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W7Fa9tOUJ92",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "Phatthiyaphaibun, W. (2018, June 4). *User manual PyThaiNLP 1.6*. Retrieved from https://github.com/PyThaiNLP/pythainlp/blob/dev/docs/pythainlp-1-6-eng.md\n",
        "\n",
        "Å˜ehÅ¯Å™ek, R. (2017, November 14). *gensim Documentation Release 0.8.6*. Retrieved from https://media.readthedocs.org/pdf/gensim/stable/gensim.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HA0_bdx1MxS",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Add Papillonbee on LINE and start to chat [here](https://line.me/R/ti/p/%40ban4934y)**\n",
        "\n",
        "**Full work is available [here](https://github.com/papillonbee/Papillonbee)**"
      ]
    }
  ]
}